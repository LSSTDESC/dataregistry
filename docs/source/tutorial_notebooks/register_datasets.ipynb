{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9337f001-5e7c-4141-a60c-5e99052aee3d",
   "metadata": {},
   "source": [
    "<div style=\"overflow: hidden;\">\n",
    "    <img src=\"images/DREGS_logo_v2.png\" width=\"300\" style=\"float: left; margin-right: 10px;\">\n",
    "</div>\n",
    "\n",
    "# Getting started: Part 1 - Registering datasets\n",
    "\n",
    "The *DESC data registry* is a means of storing and keeping track of DESC related datasets, i,e., where they are, when they were produced and what precursor datasets they depend on.\n",
    "\n",
    "This is a quick tutorial to get your started using the `dataregistry` at NERSC, both for entering your own datasets into the registry, and for finding out what datasets already exist through queries.\n",
    "\n",
    "### What we cover in this tutorial\n",
    "\n",
    "In this tutorial we will learn how to:\n",
    "\n",
    "1) Connect to the DESC data registry using the `DataRegistry` class\n",
    "2) Register a dataset\n",
    "3) Update a registered dataset with a new version\n",
    "4) Replace a dataset\n",
    "5) Modify a previously registered dataset with updated metadata\n",
    "6) Delete a dataset\n",
    "7) Registering external datasets\n",
    "8) Recap\n",
    "\n",
    "### Before we begin\n",
    "\n",
    "If you haven't done so already, check out the [getting setup](https://lsstdesc.org/dataregistry/tutorial_setup.html) page from the documentation if you want to run this tutorial interactively.\n",
    "\n",
    "A quick way to check everything is set up correctly is to run the first cell below, which should load the `dataregistry` package, and print the package version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ead9b84-4933-4213-93cb-301d79ef1167",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dataregistry\n",
    "print(\"Working with dataregistry version:\", dataregistry.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48aec2e-2b35-49ed-be76-8818d9e79b2c",
   "metadata": {},
   "source": [
    "## 1) The DataRegistry class\n",
    "\n",
    "The top-level `DataRegistry` class provides a quick and easy-to-use interface to `dataregistry` functionality.\n",
    "\n",
    "In many cases, in particular when you only need query functionality, or when you're working on your own at NERSC, a simple call with no additional arguments is adequate, e.g.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a6f3ac-15cc-4706-b230-63681ba3a4b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataregistry import DataRegistry\n",
    "\n",
    "# Establish connection to database (using defaults)\n",
    "datareg = DataRegistry()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa074027-5c6c-48d1-b79f-a6724a1bb386",
   "metadata": {},
   "source": [
    "With no arguments, the `DataRegistry` class will automatically attempt to:\n",
    "- establish a connection to the registry database using the information in your `~/.config_reg_access` and `~/.pgpass` files\n",
    "- connect to the default database schema\n",
    "- use the default NERSC \"`site`\" for the `root_dir`\n",
    "\n",
    "The root directory (`root_dir`) is the base path under which all ingested data will be copied. Other than for testing, this should generally be the NERSC `site` address."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7423fb-32d0-4a33-8e87-cd75e952512f",
   "metadata": {},
   "source": [
    "### Special cases away from the defaults\n",
    "\n",
    "If you are not connecting to the default database schema, or if your configuration file is located somewhere other than your `$HOME` directory, you must provide that information during the object creation, e.g.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85faaee8-bbc2-4879-93d5-ada69d2acbc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# When your configuration file is not in the default location\n",
    "# datareg = DataRegistry(config_file=\"/path/to/config\")\n",
    "\n",
    "# If you are connecting to a database schema other than the default, you need to specify the schema name to connect to\n",
    "# datareg = DataRegistry(schema=\"myschema\")\n",
    "\n",
    "# If you want to specify the root_dir that data is copied to (this should only be changed for testing purposes)\n",
    "#datareg = DataRegistry(root_dir=\"/my/root/dir\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7744a70-866d-419b-a083-4a4576b88727",
   "metadata": {},
   "source": [
    "### Setting universal `owner`'s and/or `owner_type`s for datasets\n",
    "\n",
    "When creating a `DataRegistry` class instance which you intend to use for registering datasets, you may optionally set a default `owner` and/or `owner_type` that will be inherited for all datasets that are registered during that instance. See details in the section \"*Registering new datasets with DataRegistry*\" below for details about `owner` and `owner_type`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d10980-cbd1-40cb-a9f5-45419b44df5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting a global owner and owner_type default value for all datasets that will be registered during this instance\n",
    "# datareg = DataRegistry(owner=\"desc\", owner_type=\"group\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d723a37-4101-496c-b385-0a2644aa7ad8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2) Registering new datasets with the `DataRegistry` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6797be3b-434f-4245-a276-a32d9294d1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some temporary text files that we can practice ingesting into the dataregistry with\n",
    "import tempfile\n",
    "\n",
    "temp_files = []\n",
    "\n",
    "# Create three temporary text files as some example data\n",
    "for i in range(3):\n",
    "    temp_file = tempfile.NamedTemporaryFile(delete=False)\n",
    "    temp_file.write(b\"This is some temporary data, number \" + str(i).encode('utf-8'))\n",
    "    temp_file.close()\n",
    "    temp_files.append(temp_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c4865f-b8b8-4caf-8e0f-1166d6bcd3c1",
   "metadata": {},
   "source": [
    "Now that we have made our connection to the database, we can register some datasets using the `Registrar` extension of the `DataRegistry` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaa5a7f-ccb1-47d3-9e9b-b62ad32287d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add new entry.\n",
    "dataset_id, execution_id = datareg.Registrar.dataset.register(\n",
    "    \"nersc_tutorial:my_first_desc_dataset\",           # `name`\n",
    "    \"1.0.0\",                                          # `version`\n",
    "    description=\"An output from some DESC code\",\n",
    "    owner=\"DESC\",\n",
    "    owner_type=\"group\",\n",
    "    is_overwritable=True,\n",
    "    old_location=temp_files[0].name\n",
    ")\n",
    "\n",
    "# This is the unique identifier assigned to the dataset from the registry\n",
    "print(f\"Dataset {dataset_id} created\")\n",
    "\n",
    "# This is the id of the execution the dataset belongs to (see next tutorial)\n",
    "print(f\"Dataset assigned to execution {execution_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ed3ffb-02f2-42ec-b2c0-643c51f8a295",
   "metadata": {
    "tags": []
   },
   "source": [
    "The code above will register a new dataset. A few notes:\n",
    "\n",
    "### The dataset name (mandatory)\n",
    "\n",
    "The first of two mandatory arguments to the `register()` function is the dataset `name`, which in our example is `nersc_tutorial:my_first_desc_dataset` (note there is nothing special about the \":\" here, the name can be any legal string). This should be any convenient, evocative name for the human, however note that the special characters `&*/\\?$` and spaces are not allowed to be part of the `name` string. The combination of `name`, `version`, `version_suffix`, `owner` and `owner_type` for any dataset must be unique in the database.\n",
    "\n",
    "The dataset `name` allows for an easy retrieval of the dataset for querying and updating.\n",
    "\n",
    "### The version string (mandatory)\n",
    "\n",
    "The second required parameter is the version string, in the semantic format, i.e., MAJOR.MINOR.PATCH. There exists also an optional ``version_suffix`` parameter, which may be used to further identify the dataset, e.g. with a value like \"rc1\" to make it clear it's only a release candidate, possibly not in its final form.\n",
    "\n",
    "\n",
    "### Owner and Owner type\n",
    "\n",
    "Datasets are registered under a given `owner`. This can be any string, however it should be informative. If no `owner` is specified, and no global `owner` was set when the `DataRegistry` instance was created, `$USER` is used as the default.\n",
    "\n",
    "One further level of classification is the `owner_type`, which can be one of `user`, `group`, `project` or `production`. If `owner_type` is not specified, and no global `owner_type` was set when the `DataRegistry` instance was created, `user` is the default.\n",
    "\n",
    "Note that `owner_type=\"production\"` datasets can only go into the production schema, and can never be overwritten (see the \"[Production Schema](https://github.com/LSSTDESC/dataregistry/tree/main/docs/source/tutorial_notebooks/production_scheme.ipynb)\" tutorial for more information).\n",
    "\n",
    "### Overwriting datasets\n",
    "\n",
    "By default, datasets in the data registry, once registered, are not overwritable. You can change this behavior by setting `is_overwritable=True` when registering your datasets. If `is_overwritable=True` on one of your previous datasets, you are then allowed to replace it, see *Replace a dataset* below.\n",
    "\n",
    "### Copying the data\n",
    "\n",
    "Registering a dataset does two things; it creates an entry in the DESC data registry database with the appropriate metadata, and it (optionally) copies the dataset contents to the `root_dir`. \n",
    "\n",
    "If the data are already at the correct relative path within the `root_dir`, leave `old_location=None` and set the `relative_path` option to point to the location of the data within the `root_dir` (see special cases section for more information on the `relative_path`). However it's likely for most users the data will need to be copied from another location to the `root_dir`. That initial location may be specified using the `old_location` parameter as we have done in the example above. \n",
    "\n",
    "In our example we have created a dummy text file as our dataset and ingested it into the data registry, however this can be any file or directory (directories will be recursively copied).\n",
    "\n",
    "Note that the dataregistry does not support registering datasets through symbolic links (symlinks).\n",
    "\n",
    "### Extra options\n",
    "\n",
    "All the `Registrar.dataset.register()` parameters we do not explicitly specify revert to their default values. For a full list of these options see the documentation [here](http://lsstdesc.org/dataregistry/reference_python.html#the-dregs-class). We would advise you to be as precise as possible when creating entries within the data registry. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6b7862-fd31-43e6-9a50-572b5cd6fff5",
   "metadata": {},
   "source": [
    "## 3) Updating a previously registered dataset with a newer version\n",
    "\n",
    "If you have a dataset that has been previously registered within the data registry, and that dataset has updates, it is simple to register the updated version.\n",
    "\n",
    "Register the new dataset using the same process as before, making sure to keep the same dataset `name`, but updating the dataset version. One can update the version in two ways: manually entering a new version string, or having the dataregistry automatically \"bump\" the dataset version by selecing either \"major\", \"minor\" or \"patch\" for the version string. For example, let's register an updated version of our dataset, bumping the minor tag (i.e., bumping 1.0.0 -> 1.1.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a65d3c0-41c1-4720-85be-10d68cef84f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new entry for an updated dataset with an updated version.\n",
    "updated_dataset_id, updated_execution_id = datareg.Registrar.dataset.register(\n",
    "    \"nersc_tutorial:my_first_desc_dataset\",\n",
    "    \"minor\", # Automatically bumps to \"1.1.0\"\n",
    "    description=\"An output from some DESC code (updated)\",\n",
    "    owner=\"DESC\",\n",
    "    owner_type=\"group\",\n",
    "    is_overwritable=True,\n",
    "    old_location=temp_files[1].name,\n",
    ")\n",
    "\n",
    "# This is the unique identifier assigned to the updated dataset from the registry\n",
    "print(f\"Dataset {updated_dataset_id} created\")\n",
    "\n",
    "# This is the id of the execution the updated dataset belongs to (see next tutorial)\n",
    "print(f\"Dataset assigned to execution {updated_execution_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43792dd5-a01b-4621-8808-c072c856f359",
   "metadata": {},
   "source": [
    "Note that both sets of data, i.e., versions `1.0.0` and `1.1.0`, still exist within the `root_dir`, and they share the same dataset name over two unique database entries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053b1348-fe1b-4426-b6ee-54b9d0d1c48d",
   "metadata": {},
   "source": [
    "## 4) Replace a dataset\n",
    "\n",
    "Rather than updating a dataset to a newer verison, one can also replace a dataset using the `replace()` method of the `Registrar` class. \n",
    "\n",
    "Replace functionally is very similar to the registration process for a new entry. The difference is that `replace()` will first delete any previous data files associated with the dataset, then register a new entry, keeping the same `name`, `version`, `version_suffix` and `relative_path` as before. This requires that the dataset you are overwriting was registered with `is_overwritable=True`.\n",
    "\n",
    "Note that whilst the data in the shared space will be overwritten, the original entries in the data registry database are never lost (a new unique entry is created each time, and the 'old' entries will obtain a `replaced` bit in their `status`, and additionally point to the dataset that overwrote them in the `replace_id` column). \n",
    "\n",
    "We can replace the first entry we made with different data as shown in the next cell. Note that `name`, `version`, `owner` and `owner_type` need to match our first entry to find the correct entry to replace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa09c52-8283-4f91-bb62-490e65acbb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new entry, overwriting the data in the `root_dir`.\n",
    "updated_dataset_id, updated_execution_id = datareg.Registrar.dataset.replace(\n",
    "    \"nersc_tutorial:my_first_desc_dataset\",\n",
    "    \"1.0.0\",                                          \n",
    "    description=\"An output from some DESC code (further updated)\",\n",
    "    owner=\"DESC\",\n",
    "    owner_type=\"group\",\n",
    "    is_overwritable=True,\n",
    "    old_location=temp_files[2].name,\n",
    ")\n",
    "\n",
    "# This is the unique identifier assigned to the replaced dataset from the registry\n",
    "print(f\"Dataset {updated_dataset_id} created\")\n",
    "\n",
    "# This is the id of the execution the replaced dataset belongs to (see next tutorial)\n",
    "print(f\"Dataset assigned to execution {updated_execution_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19afb001-d82f-448e-b40d-e4249e534286",
   "metadata": {},
   "source": [
    "Only `valid` datasets with `is_overwritable=True` set or `invalid` datasets can be replaced. Deleted datasets, or archived datasets, cannot be replaced (see next tutorial for information about a datasets `status`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc01c4e-8404-4fb4-b082-8969546f3ffc",
   "metadata": {},
   "source": [
    "## 5) Modifying the metadata of a previously registered dataset\n",
    "\n",
    "Once a dataset has been registered with the `dataregistry` it can still be modified, however only for certain metadata columns.\n",
    "\n",
    "We can check and see what metadata columns we are allowed to modify by running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4252ce7e-7dea-4404-ae61-19b8ca0be2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What columns in the dataset table are modifiable?\n",
    "print(datareg.Registrar.dataset.get_modifiable_columns())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddf3078-91e8-4f4e-beaf-bd0d065c912a",
   "metadata": {},
   "source": [
    "To modify the metadata of a dataset entry we call the `.modify()` function for the appropriate schema table, which accepts the unique entry ID of the dataset we wish to modify and a key-value pair dictionary with the modifications we wish to make.\n",
    "\n",
    "For example, if we want to update the `description` column of our first example entry above we would do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f20548e-148b-44af-a22a-b1e259d5e994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A key-value dict of the columns we want to update, with their new values\n",
    "update_dict = {\"description\": \"My new updated description\"}\n",
    "\n",
    "datareg.Registrar.dataset.modify(dataset_id, update_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cbe713-b6d0-4db7-ba67-20775087f784",
   "metadata": {},
   "source": [
    "## 6) Deleting a dataset in the dataregistry\n",
    "\n",
    "To delete a dataset entry from the dataregistry we call the .delete() function which accepts one argument, the dataset_id of the entry you wish to delete, e.g.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becbc567-e7a0-479d-8a1d-4a315d781bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete dataset with entry ID == dataset_id\n",
    "datareg.Registrar.dataset.delete(dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594c3b1a-8491-4f6e-b47b-97de00cccd9b",
   "metadata": {},
   "source": [
    "Note that this will remove the dataset data stored under the root_dir, however the entry within the registry database will remain (with an updated status indicated the dataset was deleted)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6909cf-9826-4533-8b91-bb7a63079b37",
   "metadata": {},
   "source": [
    "## 7) Registering external datasets\n",
    "\n",
    "Typically when we register datasets we are asking the `dataregistry` to collate provenance data for the dataset and to physically manage the data (either copy the data to the central `root_dir` or verify that it already exists there).\n",
    "\n",
    "However the `dataregistry` can also accept entries for \"external\" datasets, e.g., those located off site and not controlled by DESC. These will only be entries in the database, for querying purposes, and no physical data (managed by the `dataregistry`) will be associated with those entries.\n",
    "\n",
    "When registering an external dataset into the `dataregistry` you must provide either a `contact_email` or `url` during registration, and set `location_type=\"external\"`. The remaining provenance information is the same as before.\n",
    "\n",
    "For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e959f76f-b5e1-43a6-9932-ee1866cc398d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new external dataset entry.\n",
    "dataset_id, execution_id = datareg.Registrar.dataset.register(\n",
    "    \"nersc_tutorial:external_dataset\",\n",
    "    \"0.0.1\",\n",
    "    description=\"Images from some external observatory\",\n",
    "    is_overwritable=True,\n",
    "    location_type=\"external\",\n",
    "    url=\"www.data.com\",\n",
    ")\n",
    "\n",
    "# This is the unique identifier assigned to the updated dataset from the registry\n",
    "print(f\"Dataset {dataset_id} created\")\n",
    "\n",
    "# This is the id of the execution the updated dataset belongs to (see next tutorial)\n",
    "print(f\"Dataset assigned to execution {execution_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56975091-aee1-49f4-93a4-b1252af94fa2",
   "metadata": {},
   "source": [
    "## 8) Recap\n",
    "\n",
    "- To register a dataset use the `Registrar.dataset.register()` function\n",
    "- You can update a dataset with a newer version by registering with the same `name` as the previous dataset, but an updated `version`\n",
    "- You can replace the data and keep the same `name`/`version`/`relative_path` of a previous dataset using the `Registrar.dataset.replace()` function\n",
    "- Some fields of registered datasets can be modified later using the `Registrar.dataset.modify()` function\n",
    "- Datasets can be deleted (only the data, the database entry will remain) using the `Registrar.dataset.delete()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22328726-eecc-437b-b3ee-46aba7c06ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
