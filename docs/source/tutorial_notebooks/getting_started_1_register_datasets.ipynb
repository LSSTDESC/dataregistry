{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9337f001-5e7c-4141-a60c-5e99052aee3d",
   "metadata": {},
   "source": [
    "<div style=\"overflow: hidden;\">\n",
    "    <img src=\"images/DREGS_logo_v2.png\" width=\"300\" style=\"float: left; margin-right: 10px;\">\n",
    "</div>\n",
    "\n",
    "# Getting started: Part 1 - Registering datasets\n",
    "\n",
    "The *DESC data registry* is a means of storing and keeping track of DESC related datasets, i,e., where they are, when they were produced and what precursor datasets they depend on.\n",
    "\n",
    "This is a quick tutorial to get your started using the `dataregistry` at NERSC, both for entering your own datasets into the registry, and for finding out what datasets already exist through queries.\n",
    "\n",
    "### What we cover in this tutorial\n",
    "\n",
    "In this tutorial we will learn how to:\n",
    "\n",
    "1) Connect to the DESC data registry using the `DataRegistry` class\n",
    "2) Register a dataset\n",
    "3) Update a registered dataset with a new version\n",
    "4) Modify a previously registered dataset with updated metadata\n",
    "5) Delete a dataset\n",
    "6) Special cases\n",
    "    - Registering external datasets\n",
    "    - Tagging datasets with keywords\n",
    "    - Manually specifying the relative path\n",
    "\n",
    "### Before we begin\n",
    "\n",
    "If you haven't done so already, check out the [getting setup](https://lsstdesc.org/dataregistry/tutorial_setup.html) page from the documentation if you want to run this tutorial interactively.\n",
    "\n",
    "A quick way to check everything is set up correctly is to run the first cell below, which should load the `dataregistry` package, and print the package version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ead9b84-4933-4213-93cb-301d79ef1167",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dataregistry\n",
    "print(\"Working with dataregistry version:\", dataregistry.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48aec2e-2b35-49ed-be76-8818d9e79b2c",
   "metadata": {},
   "source": [
    "## 1) The DataRegistry class\n",
    "\n",
    "The top-level `DataRegistry` class provides a quick and easy-to-use interface to `dataregistry` functionality.\n",
    "\n",
    "In many cases, in particular when you only need query functionality, or when you're working on your own at NERSC, a simple call with no additional arguments is adequate, e.g.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a6f3ac-15cc-4706-b230-63681ba3a4b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataregistry import DataRegistry\n",
    "\n",
    "# Establish connection to database (using defaults)\n",
    "datareg = DataRegistry()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa074027-5c6c-48d1-b79f-a6724a1bb386",
   "metadata": {},
   "source": [
    "With no arguments, the `DataRegistry` class will automatically attempt to:\n",
    "- establish a connection to the registry database using the information in your `~/.config_reg_access` and `~/.pgpass` files\n",
    "- connect to the default database schema\n",
    "- use the default NERSC \"`site`\" for the `root_dir`\n",
    "\n",
    "The root directory (`root_dir`) is the base path under which all ingested data will be copied. Other than for testing, this should generally be the NERSC `site` address."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7423fb-32d0-4a33-8e87-cd75e952512f",
   "metadata": {},
   "source": [
    "### Special cases away from the defaults\n",
    "\n",
    "If you are not connecting to the default database schema, or if your configuration file is located somewhere other than your `$HOME` directory, you must provide that information during the object creation, e.g.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85faaee8-bbc2-4879-93d5-ada69d2acbc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# When your configuration file is not in the default location\n",
    "# datareg = DataRegistry(config_file=\"/path/to/config\")\n",
    "\n",
    "# If you are connecting to a database schema other than the default, you need to specify the schema name to connect to\n",
    "# datareg = DataRegistry(schema=\"myschema\")\n",
    "\n",
    "# If you want to specify the root_dir that data is copied to (this should only be changed for testing purposes)\n",
    "#datareg = DataRegistry(root_dir=\"/my/root/dir\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7744a70-866d-419b-a083-4a4576b88727",
   "metadata": {},
   "source": [
    "### Setting universal `owner`'s and/or `owner_type`s for datasets\n",
    "\n",
    "When creating a `DataRegistry` class instance which you intend to use for registering datasets, you may optionally set a default `owner` and/or `owner_type` that will be inherited for all datasets that are registered during that instance. See details in the section \"*Registering new datasets with DataRegistry*\" below for details about `owner` and `owner_type`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d10980-cbd1-40cb-a9f5-45419b44df5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting a global owner and owner_type default value for all datasets that will be registered during this instance\n",
    "# datareg = DataRegistry(owner=\"desc\", owner_type=\"group\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d723a37-4101-496c-b385-0a2644aa7ad8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2) Registering new datasets with the `DataRegistry` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6797be3b-434f-4245-a276-a32d9294d1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some temporary text files that we can practice ingesting into the dataregistry with\n",
    "import tempfile\n",
    "\n",
    "temp_files = []\n",
    "\n",
    "# Create three temporary text files as some example data\n",
    "for i in range(3):\n",
    "    temp_file = tempfile.NamedTemporaryFile(delete=False)\n",
    "    temp_file.write(b\"This is some temporary data, number \" + str(i).encode('utf-8'))\n",
    "    temp_file.close()\n",
    "    temp_files.append(temp_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c4865f-b8b8-4caf-8e0f-1166d6bcd3c1",
   "metadata": {},
   "source": [
    "Now that we have made our connection to the database, we can register some datasets using the `Registrar` extension of the `DataRegistry` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaa5a7f-ccb1-47d3-9e9b-b62ad32287d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add new entry.\n",
    "dataset_id, execution_id = datareg.Registrar.dataset.register(\n",
    "    \"nersc_tutorial:my_first_desc_dataset\",\n",
    "    \"1.0.0\",\n",
    "    description=\"An output from some DESC code\",\n",
    "    owner=\"DESC\",\n",
    "    owner_type=\"group\",\n",
    "    is_overwritable=True,\n",
    "    old_location=temp_files[0].name\n",
    ")\n",
    "\n",
    "# This is the unique identifier assigned to the dataset from the registry\n",
    "print(f\"Dataset {dataset_id} created\")\n",
    "\n",
    "# This is the id of the execution the dataset belongs to (see next tutorial)\n",
    "print(f\"Dataset assigned to execution {execution_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ed3ffb-02f2-42ec-b2c0-643c51f8a295",
   "metadata": {
    "tags": []
   },
   "source": [
    "This will register a new dataset. A few notes:\n",
    "\n",
    "### The dataset name (mandatory)\n",
    "\n",
    "The first of two mandatory arguments to the `register()` function is the dataset `name`, which in our example is `nersc_tutorial:my_first_desc_dataset` (note there is nothing special about the \":\" here, the name can be any legal string). This should be any convenient, evocative name for the human, however note that the special characters `&*/\\?$` and spaces are not allowed to be part of the `name` string. The combination of `name`, `version` and `version_suffix` for any dataset must be unique in the database.\n",
    "\n",
    "The dataset `name` allows for an easy retrieval of the dataset for querying and updating.\n",
    "\n",
    "### The version string (mandatory)\n",
    "\n",
    "The second required parameter is the version string, in the semantic format, i.e., MAJOR.MINOR.PATCH. There exists also an optional ``version_suffix`` parameter, which may be used to further identify the dataset, e.g. with a value like \"rc1\" to make it clear it's only a release candidate, possibly not in its final form.\n",
    "\n",
    "\n",
    "### Owner and Owner type\n",
    "\n",
    "Datasets are registered under a given `owner`. This can be any string, however it should be informative. If no `owner` is specified, and no global `owner` was set when the `DataRegistry` instance was created, `$USER` is used as the default.\n",
    "\n",
    "One further level of classification is the `owner_type`, which can be one of `user`, `group`, `project` or `production`. If `owner_type` is not specified, and no global `owner_type` was set when the `DataRegistry` instance was created, `user` is the default.\n",
    "\n",
    "Note that `owner_type=\"production\"` datasets can only go into the production schema, and can never be overwritten (see the \"[Production Schema](https://github.com/LSSTDESC/dataregistry/tree/main/docs/source/tutorial_notebooks/production_scheme.ipynb)\" tutorial for more information).\n",
    "\n",
    "### Overwriting datasets\n",
    "\n",
    "By default, datasets in the data registry, once registered, are not overwritable. You can change this behavior by setting `is_overwritable=True` when registering your datasets. If `is_overwritable=True` on one of your previous datasets, you can register a new dataset with the same combination of `relative_path`, `owner` and `owner_type` as before (be warned that any previous data stored under this path will be deleted first). \n",
    "\n",
    "Note that whilst the data in the shared space will be overwritten with each registration when `is_overwritable=True`, the original entries in the data registry database are never lost (a new unique entry is created each time, and the 'old' entries will obtain `True` for their `is_overwritten` column).\n",
    "\n",
    "### Copying the data\n",
    "\n",
    "Registering a dataset does two things; it creates an entry in the DESC data registry database with the appropriate metadata, and it (optionally) copies the dataset contents to the `root_dir`. \n",
    "\n",
    "If the data are already at the correct relative path within the `root_dir`, then the `relative_path` option, pointing to the location of the data, needs to be provided. However it's likely for most users the data will need to be copied from another location to the `root_dir`. That initial location may be specified using the `old_location` parameter as we have done in the example above. \n",
    "\n",
    "In our example we have created a dummy text file as our dataset and ingested it into the data registry, however this can be any file or directory (directories will be recursively copied).\n",
    "\n",
    "### Extra options\n",
    "\n",
    "All the `Registrar.dataset.register()` parameters we do not explicitly specify revert to their default values. For a full list of these options see the documentation [here](http://lsstdesc.org/dataregistry/reference_python.html#the-dregs-class). We would advise you to be as precise as possible when creating entries within the data registry. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6b7862-fd31-43e6-9a50-572b5cd6fff5",
   "metadata": {},
   "source": [
    "## 3) Updating a previously registered dataset with a newer version\n",
    "\n",
    "If you have a dataset that has been previously registered within the data registry, and that dataset has updates, you have three options for how to handle the new entry:\n",
    "\n",
    "- You can enter it as a newer version of the previous dataset (recommended in most situations)\n",
    "- You can overwrite the existing dataset with the new data (only if the previous dataset was entered with is_overwritable=True)\n",
    "- You can enter it as a completely new standalone dataset with no links to the previous dataset\n",
    "\n",
    "For 1. we register a new dataset as before, making sure to keep the same dataset `name`, but updating the dataset version. One can update the version in two ways: manually entering a new version string, or having the dataregistry automatically \"bump\" the dataset version by selecing either \"major\", \"minor\" or \"patch\" for the version string. For example, let's register an updated version of our dataset, bumping the minor tag (i.e., bumping 1.0.0 -> 1.1.0).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a65d3c0-41c1-4720-85be-10d68cef84f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new entry for an updated dataset with an updated version.\n",
    "updated_dataset_id, updated_execution_id = datareg.Registrar.dataset.register(\n",
    "    \"nersc_tutorial:my_first_desc_dataset\",\n",
    "    \"minor\", # Automatically bumps to \"1.1.0\"\n",
    "    description=\"An output from some DESC code (updated)\",\n",
    "    owner=\"DESC\",\n",
    "    owner_type=\"group\",\n",
    "    is_overwritable=True,\n",
    "    old_location=temp_files[1].name,\n",
    ")\n",
    "\n",
    "# This is the unique identifier assigned to the updated dataset from the registry\n",
    "print(f\"Dataset {updated_dataset_id} created\")\n",
    "\n",
    "# This is the id of the execution the updated dataset belongs to (see next tutorial)\n",
    "print(f\"Dataset assigned to execution {updated_execution_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43792dd5-a01b-4621-8808-c072c856f359",
   "metadata": {},
   "source": [
    "Note that both sets of data, i.e., versions `1.0.0` and `1.1.0`, still exist, and they share the same dataset name.\n",
    "\n",
    "For 2., to update a previous dataset and overwrite the existing data in the `root_dir`, we have to pass the `relative_path` of the existing dataset (see Section 6 for more details on the `relative_path`). For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62733b65-e915-43d2-b944-cac60b9e9ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new entry, overwriting the data in the `root_dir`.\n",
    "updated_dataset_id, updated_execution_id = datareg.Registrar.dataset.register(\n",
    "    \"nersc_tutorial:my_first_desc_dataset\",\n",
    "    \"patch\", # Automatically bumps to \"1.1.1\"\n",
    "    description=\"An output from some DESC code (further updated)\",\n",
    "    owner=\"DESC\",\n",
    "    owner_type=\"group\",\n",
    "    is_overwritable=True,\n",
    "    old_location=temp_files[2].name,\n",
    "    relative_path=\"nersc_tutorial:my_first_desc_dataset_1.1.0\", # We overwrite the old data at this path\n",
    ")\n",
    "\n",
    "# This is the unique identifier assigned to the updated dataset from the registry\n",
    "print(f\"Dataset {updated_dataset_id} created\")\n",
    "\n",
    "# This is the id of the execution the updated dataset belongs to (see next tutorial)\n",
    "print(f\"Dataset assigned to execution {updated_execution_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12edcd2c-af04-4d5e-9891-080feada1040",
   "metadata": {},
   "source": [
    "will create a new dataset, version 1.1.1, but the new data has overwritten the data for version 1.1.0.\n",
    "\n",
    "For 3. simply follow the procedure above for registering a new dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc01c4e-8404-4fb4-b082-8969546f3ffc",
   "metadata": {},
   "source": [
    "## 4) Modifying the metadata of a previously registered dataset\n",
    "\n",
    "Once a dataset has been registered with the `dataregistry` it can still be modified, however only for certain metadata columns.\n",
    "\n",
    "We can check and see what metadata columns we are allowed to modify by running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4252ce7e-7dea-4404-ae61-19b8ca0be2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What columns in the dataset table are modifiable?\n",
    "print(datareg.Registrar.dataset.get_modifiable_columns())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddf3078-91e8-4f4e-beaf-bd0d065c912a",
   "metadata": {},
   "source": [
    "To modify the metadata of a dataset entry we call the `.modify()` function for the appropriate schema table, which accepts the unique entry ID of the dataset we wish to modify and a key-value pair dictionary with the modifications we wish to make.\n",
    "\n",
    "For example, if we want to update the `description` column of our first example entry above we would do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f20548e-148b-44af-a22a-b1e259d5e994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A key-value dict of the columns we want to update, with their new values\n",
    "update_dict = {\"description\": \"My new updated description\"}\n",
    "\n",
    "datareg.Registrar.dataset.modify(dataset_id, update_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cbe713-b6d0-4db7-ba67-20775087f784",
   "metadata": {},
   "source": [
    "## 5) Deleting a dataset in the dataregistry\n",
    "\n",
    "To delete a dataset entry from the dataregistry we call the .delete() function which accepts one argument, the dataset_id of the entry you wish to delete, e.g.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becbc567-e7a0-479d-8a1d-4a315d781bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete dataset with entry ID == dataset_id\n",
    "datareg.Registrar.dataset.delete(dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594c3b1a-8491-4f6e-b47b-97de00cccd9b",
   "metadata": {},
   "source": [
    "Note that this will remove the dataset data stored under the root_dir, however the entry within the registry database will remain (with an updated status indicated the dataset was deleted)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6909cf-9826-4533-8b91-bb7a63079b37",
   "metadata": {},
   "source": [
    "## 6) Special cases\n",
    "\n",
    "### Registering external datasets\n",
    "\n",
    "Typically when we register datasets we are asking the `dataregistry` to collate provenance data for the dataset and to physically manage the data (i.e., to copy the data to the central `root_dir`).\n",
    "\n",
    "However the `dataregistry` can also accept entries for \"external\" datasets, e.g., those located off site and not controlled by DESC. These will only be entries in the database, for querying purposes, and no physical data (managed by the `dataregistry`) will be associated with those entries.\n",
    "\n",
    "When registering an external dataset into the `dataregistry` you must provide either a `contact_email` or `url` during registration, and set `location_type=\"external\"`. The remaining provenance information is the same as before.\n",
    "\n",
    "For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e959f76f-b5e1-43a6-9932-ee1866cc398d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new external dataset entry.\n",
    "dataset_id, execution_id = datareg.Registrar.dataset.register(\n",
    "    \"nersc_tutorial:external_dataset\",\n",
    "    \"0.0.1\",\n",
    "    description=\"Images from some external observatory\",\n",
    "    is_overwritable=True,\n",
    "    location_type=\"external\",\n",
    "    url=\"www.data.com\",\n",
    ")\n",
    "\n",
    "# This is the unique identifier assigned to the updated dataset from the registry\n",
    "print(f\"Dataset {dataset_id} created\")\n",
    "\n",
    "# This is the id of the execution the updated dataset belongs to (see next tutorial)\n",
    "print(f\"Dataset assigned to execution {execution_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a78928d-0e0f-4fc4-9022-ba8d60e8f941",
   "metadata": {},
   "source": [
    "### Tagging datasets with keywords\n",
    "\n",
    "To make datasets broadly easier for people to find, they can be tagged with one or more keywords.\n",
    "\n",
    "Keywords are restricted to those within a predefined list, to see the list run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560b857c-7d94-44ad-9637-0b107cd42259",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datareg.Registrar.dataset.get_keywords())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a0498b-06ff-479b-aa14-ccaf935b1489",
   "metadata": {},
   "source": [
    "Or run \n",
    "\n",
    "```bash\n",
    "dregs show keywords\n",
    "```\n",
    "\n",
    "from the command line.\n",
    "\n",
    "Keywords are passed as a list of strings during dataset registration. For example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44581049-1d15-44f0-b1ed-34cff6cdb45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new dataset entry with keywords.\n",
    "dataset_id, execution_id = datareg.Registrar.dataset.register(\n",
    "    \"nersc_tutorial:keywords_dataset\",\n",
    "    \"0.0.1\",\n",
    "    description=\"A dataset with some keywords tagged\",\n",
    "    is_overwritable=True,\n",
    "    keywords=[\"simulation\"],\n",
    "    old_location=temp_files[0].name\n",
    ")\n",
    "\n",
    "# This is the unique identifier assigned to the updated dataset from the registry\n",
    "print(f\"Dataset {dataset_id} created\")\n",
    "\n",
    "# This is the id of the execution the updated dataset belongs to (see next tutorial)\n",
    "print(f\"Dataset assigned to execution {execution_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedf7fb7-704d-4978-bb18-0f27c6c037b0",
   "metadata": {},
   "source": [
    "will create a dataset tagged with the keyword \"simulation\".\n",
    "\n",
    "We can also append keywords to a dataset after it has been registered using the `add_keywords()` function, providing a list of the new keywords we want to add, e.g.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09478b87-7d5a-4814-85c7-49f90e0db45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of keywords to add to dataset\n",
    "updated_keywords = [\"observation\"]\n",
    "\n",
    "datareg.Registrar.dataset.add_keywords(dataset_id, updated_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1aaf82-92cf-4c8f-8c1f-c7a53a27f661",
   "metadata": {},
   "source": [
    "Note keywords will never be duplicated, i.e., if you `add_keywords()` with a list containing a keyword that is already tagged for that dataset, no new duplicate keyword entry will be created.\n",
    "\n",
    "We can return all datasets tagged with certain keywords with a simple query, which we cover in the next tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4af4a61-3918-4334-92d8-1111cb9d5aac",
   "metadata": {},
   "source": [
    "### Specifying the relative path\n",
    "\n",
    "Datasets are registered within the registry under a path relative to the root directory (`root_dir`), which, by default, is a shared space at NERSC.\n",
    "\n",
    "By default, the relative_path is constructed from the name, version and version_suffix (if there is one), in the format `relative_path=<name>/<version>_<version_suffix>`. However, one can also manually select the relative_path during registration, for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc0d5b6-f50a-4646-bc1b-7d9e829e91bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new entry with a manual relative path.\n",
    "datareg.Registrar.dataset.register(\n",
    "    \"nersc_tutorial:my_desc_dataset_with_relative_path\",\n",
    "    \"1.0.0\",\n",
    "    relative_path=\"nersc_tutorial/my_desc_dataset\",\n",
    "    old_location=temp_files[0].name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcacf4b1-dcb3-4632-af6d-a5aa6389100f",
   "metadata": {},
   "source": [
    "will register a dataset under the `relative_path` of `nersc_tutorial/my_desc_dataset`.\n",
    "\n",
    "For those interested, the eventual full path for the dataset will be `<root_dir>/<schema>/<owner_type>/<owner>/<relative_path>`. This means that the combination of `relative_path`, `owner` and `owner_type` must be unique within the registry, and therefore cannot already be taken when you register a new dataset (an exception to this is if you allow your datasets to be overwritable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be07a214-ca40-4e3f-a07f-a4db7e4038fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### The relative path\n",
    "\n",
    "Datasets are registered within the registry under a path relative to the root directory (`root_dir`), which, by default, is a shared space at NERSC. For those interested, the eventual full path for the dataset will be `<root_dir>/<schema>/<owner_type>/<owner>/<relative_path>`. This means that the combination of `relative_path`, `owner` and `owner_type` must be unique within the registry, and therefore cannot already be taken when you register a new dataset (an exception to this is if you allow your datasets to be overwritable, see below). \n",
    "\n",
    "The relative path is one of the two required parameters you must specify when registering a dataset (in the example here our relative path is `nersc_tutorial/my_desc_dataset`)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
