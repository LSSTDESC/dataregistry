{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9337f001-5e7c-4141-a60c-5e99052aee3d",
   "metadata": {},
   "source": [
    "<div style=\"overflow: hidden;\">\n",
    "    <img src=\"images/DREGS_logo_v2.png\" width=\"300\" style=\"float: left; margin-right: 10px;\">\n",
    "</div>\n",
    "\n",
    "# Getting started: Part 2 - A closer look at datasets\n",
    "\n",
    "The *DESC data registry* is a means of storing and keeping track of DESC related datasets, i,e., where they are, when they were produced and what precursor datasets they depend on.\n",
    "\n",
    "This is a quick tutorial to get your started using the `dataregistry` at NERSC, both for entering your own datasets into the registry, and for finding out what datasets already exist through queries.\n",
    "\n",
    "### What we cover in this tutorial\n",
    "\n",
    "In this tutorial we will learn about:\n",
    "\n",
    "1) Tagging datasets with `keywords`\n",
    "2) The `relative_path` and where datasets are stored\n",
    "3) The dataset `status` and history\n",
    "\n",
    "### Before we begin\n",
    "\n",
    "If you haven't done so already, check out the [getting setup](https://lsstdesc.org/dataregistry/tutorial_setup.html) page from the documentation if you want to run this tutorial interactively.\n",
    "\n",
    "A quick way to check everything is set up correctly is to run the first cell below, which should load the `dataregistry` package, and print the package version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ead9b84-4933-4213-93cb-301d79ef1167",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Come up with a random owner name to avoid clashes\n",
    "from random import randint\n",
    "import os\n",
    "OWNER = \"tutorial_\" + os.environ.get('USER') + '_' + str(randint(0,int(1e6)))\n",
    "\n",
    "import dataregistry\n",
    "print(f\"Working with dataregistry version: {dataregistry.__version__} as random owner {OWNER}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2f92bf-9048-421e-b896-292eb00542c8",
   "metadata": {},
   "source": [
    "**Note** that running some of the cells below may fail, especially if run multiple times. This will likely be from clashes with the unique constraints within the database (hopefully the error output is informative). In these events either; (1) run the cell above to establish a new database connection with a new random user, or (2) manually change the conflicting database column(s) that are clashing during registration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0390becc-1f14-495c-bba5-67213e464f1d",
   "metadata": {},
   "source": [
    "## 1) Tagging datasets with keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eabcd0-b05e-4e87-9ed1-6450ac196b05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataregistry import DataRegistry\n",
    "\n",
    "# Establish connection to the tutorial schema\n",
    "datareg = DataRegistry(schema=\"tutorial_working\", owner=OWNER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a78928d-0e0f-4fc4-9022-ba8d60e8f941",
   "metadata": {},
   "source": [
    "To make datasets broadly easier for people to find, they can be tagged with one or more keywords.\n",
    "\n",
    "Keywords are restricted to those within a predefined list, to see the list run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560b857c-7d94-44ad-9637-0b107cd42259",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(datareg.Registrar.dataset.get_keywords())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a0498b-06ff-479b-aa14-ccaf935b1489",
   "metadata": {},
   "source": [
    "Or run `dregs show keywords` from the command line.\n",
    "\n",
    "Keywords are passed as a list of strings during dataset registration. For example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44581049-1d15-44f0-b1ed-34cff6cdb45a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add new dataset entry with keywords.\n",
    "dataset_id, execution_id = datareg.Registrar.dataset.register(\n",
    "    \"nersc_tutorial:keywords_dataset\",\n",
    "    \"0.0.1\",\n",
    "    description=\"A dataset with some keywords tagged\",\n",
    "    is_overwritable=True,\n",
    "    keywords=[\"simulation\"],\n",
    "    location_type=\"dummy\", # for testing, means we need no data\n",
    ")\n",
    "\n",
    "# This is the unique identifier assigned to the updated dataset from the registry\n",
    "print(f\"Dataset {dataset_id} created\")\n",
    "\n",
    "# This is the id of the execution the updated dataset belongs to (see next tutorial)\n",
    "print(f\"Dataset assigned to execution {execution_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedf7fb7-704d-4978-bb18-0f27c6c037b0",
   "metadata": {},
   "source": [
    "will create a dataset tagged with the keyword \"simulation\".\n",
    "\n",
    "We can also append keywords to a dataset after it has been registered using the `add_keywords()` function, providing a list of the new keywords we want to add, e.g.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09478b87-7d5a-4814-85c7-49f90e0db45d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List of keywords to add to dataset\n",
    "updated_keywords = [\"observation\"]\n",
    "\n",
    "datareg.Registrar.dataset.add_keywords(dataset_id, updated_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1aaf82-92cf-4c8f-8c1f-c7a53a27f661",
   "metadata": {},
   "source": [
    "Note keywords will never be duplicated, i.e., if you `add_keywords()` with a list containing a keyword that is already tagged for that dataset, no new duplicate keyword entry will be created.\n",
    "\n",
    "We can return all datasets tagged with certain keywords with a simple query, which we cover in the next tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4af4a61-3918-4334-92d8-1111cb9d5aac",
   "metadata": {},
   "source": [
    "## 2) The relative path and where datasets are stored\n",
    "\n",
    "The files and directories of registered datasets are stored under a path relative to the root directory (`root_dir`), which, by default, is a shared space at NERSC.\n",
    "\n",
    "By default, when not manually specified, the `relative_path` is constructed from the `name` and `version`, in the format `relative_path=.gen_paths/<name>_<version>/`. \n",
    "\n",
    "One can manually select the `relative_path` during registration if they explicitly care about where the data is located relative to the `root_dir`, for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc0d5b6-f50a-4646-bc1b-7d9e829e91bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add new entry with a manual relative path.\n",
    "datareg.Registrar.dataset.register(\n",
    "    \"nersc_tutorial:my_desc_dataset_with_relative_path\",\n",
    "    \"1.0.0\",\n",
    "    relative_path=f\"NERSC_tutorial/{OWNER}/my_desc_dataset\",\n",
    "    location_type=\"dummy\", # for testing, means we need no actual data to exist\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcacf4b1-dcb3-4632-af6d-a5aa6389100f",
   "metadata": {},
   "source": [
    "will register a dataset under the `relative_path` of `nersc_tutorial/my_desc_dataset`.\n",
    "\n",
    "If the registered dataset was a single file, the `relative_path` will be the explicit (relative) pathname to that file, e.g., `.gen_paths/mydataset_1.0.0/myfile.txt` or `my/manual/path/myfile.txt`. If the registered dataset was a directory, the `relative_path` is the pathname to the directory containing the dataset contents.\n",
    "\n",
    "For those interested, the eventual full path for the dataset will be `<root_dir>/<schema>/<owner_type>/<owner>/<relative_path>`. Naturally, the `relative_path` you select cannot already be taken by another dataset (an error will be raised in this case), and any manually specified `relative_path` cannot start with `.gen_paths` as this directory is reserved for autogenerated `relative_path`s.\n",
    "\n",
    "When you overwrite a previous dataset entry using the `replace()` function, the original `relative_path` at registration (automatically generated or manual) will be used.\n",
    "\n",
    "One can construct the full absolute path to a dataregistry file using the `get_dataset_absolute_path()` helper function, e.g.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f193290d-892a-47b6-8e91-8e94a10d506f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the full absolute path to a dataset using the dataset id\n",
    "absolute_path = datareg.Query.get_dataset_absolute_path(dataset_id)\n",
    "\n",
    "print(f\"The absolute path for {dataset_id} is {absolute_path}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088678bc-fa5b-47fd-b23c-f1f3b0742299",
   "metadata": {},
   "source": [
    "## 3) The dataset `status` and history\n",
    "\n",
    "Datasets can go through multiple changes from the point they are registered. A partial history of the dataset and its current status is embedded within the metadata.\n",
    "\n",
    "### The dataset status\n",
    "\n",
    "The `status` row for a dataset is an integer bitmask value that reports the current state of a dataset. The four bits are, in order:\n",
    "\n",
    "- bit 0: `valid`: This should generally always be true. If the valid bit is false, it means that there was an issue during registration, most likely a failure during data copying.\n",
    "- bit 1: `deleted`: If this bit is true, the files belonging to the dataset have been deleted from the `root_dir`, the entry in the database persists.\n",
    "- bit 2: `archived`: If this bit is true, the dataset has been archived from the `root_dir` to `archive_path`, the entry in the database persists.\n",
    "- bit 3: `replaced`: When a dataset is overwritten using the `replace()` function, a new entry is formed in the database each time, with the old entry pointing to the new one. Replaced entried with have true for their `replaced` bit.\n",
    "\n",
    "There are utillities in the `dataregistry` package to help decipher a datasets status. For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718d1cd8-4517-4597-9e36-e403e219cef2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataregistry.registrar.dataset_util import get_dataset_status\n",
    "\n",
    "# The `get_dataset_status` function takes in a dataset `status` and a bit index, and returns if that bit is True or False\n",
    "dataset_status = 1\n",
    "\n",
    "# Is dataset valid?\n",
    "print(f\"Dataset is valid: {get_dataset_status(dataset_status, 'valid')}\")\n",
    "\n",
    "# Is dataset replaced?\n",
    "print(f\"Dataset is replaced: {get_dataset_status(dataset_status, 'replaced')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfdc521-a95d-4eba-a8e6-db449d9f24d8",
   "metadata": {},
   "source": [
    "### The dataset history\n",
    "\n",
    "There are some columns for datasets that track a rudamentary history:\n",
    "\n",
    "- `register_date`: Stores when the dataset was registered\n",
    "- `creation_date`: Is when the dataset itself was created, read from the file metadata automataically (note this can be manually overwritten during dataset registration)\n",
    "- `archive_date`: If the dataset has been archived out of the registry `root_dir`, this is when it happened\n",
    "- `delete_date`: If the dataset has been deleted, this is when it happened. There is also `delete_uid`, which is the user ID of the person that deleted the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944b88fb-5bf7-4678-a6a5-ebf66d6b25e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DREGS-env",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
