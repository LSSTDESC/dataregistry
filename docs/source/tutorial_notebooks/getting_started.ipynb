{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9337f001-5e7c-4141-a60c-5e99052aee3d",
   "metadata": {},
   "source": [
    "<img src=\"../_static/DREGS_logo_v2.png\" width=\"300\"/>\n",
    "\n",
    "# Getting started with the DESC data registry\n",
    "\n",
    "The *DESC data registry* is a means of storing and keeping track of DESC related datasets, i,e., where they are, when they were produced and what precursor datasets they depend on.\n",
    "\n",
    "This is a quick tutorial to get your started using the `dataregistry` at NERSC, both for entering your own datasets into the registry, and for finding out what datasets already exist through queries.\n",
    "\n",
    "### What we cover in this tutorial\n",
    "\n",
    "In this tutorial we will learn how to:\n",
    "\n",
    "- Connect to the DESC data registry using the `DataRegistry` class\n",
    "- Register a dataset\n",
    "- Perform a simple query \n",
    "\n",
    "### Before we begin\n",
    "\n",
    "If you haven't done so already, check out the \"getting setup\" page from the docs if you want to run this tutorial interactively.\n",
    "\n",
    "A quick way to check everything is set up correctly is to run the first cell below, which should load the `dataregistry` package, and print the package version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ead9b84-4933-4213-93cb-301d79ef1167",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dataregistry\n",
    "print(\"Working with dataregistry version:\", dataregistry.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48aec2e-2b35-49ed-be76-8818d9e79b2c",
   "metadata": {},
   "source": [
    "## The DataRegistry class\n",
    "\n",
    "The top-level `DataRegistry` class provides a quick and easy-to-use interface to `dataregistry` functionality.\n",
    "\n",
    "Upon creation, the `DataRegistry` class automatically establishes a connection to the DESC data registry database using the information in your `~/.config_reg_access` and `~/.pgpass` files.\n",
    "\n",
    "In many cases, in particular when you only need query functionality, or when you're working on your own at NERSC, a simple call with no additional arguments is adequate, e.g.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a6f3ac-15cc-4706-b230-63681ba3a4b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataregistry import DataRegistry\n",
    "\n",
    "# Establish connection to database (using defaults)\n",
    "datareg = DataRegistry()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7423fb-32d0-4a33-8e87-cd75e952512f",
   "metadata": {},
   "source": [
    "However, if you are not connecting to the default database schema, or if your configuration file is located somewhere other than your `$HOME` directory, you must provide that information during the object creation, e.g.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85faaee8-bbc2-4879-93d5-ada69d2acbc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# When your configuration file is not in the default location\n",
    "# datareg = DataRegistry(config_file=\"/path/to/config\")\n",
    "\n",
    "# If you are connecting to a database schema other than the default, you need to specify the schema name to connect to\n",
    "# datareg = DataRegistry(schema_version=\"myschema\")\n",
    "\n",
    "# If you want to specify the root_dir that data is copied to (this should only be changed for testing purposes)\n",
    "# datareg = DataRegistry(root_dir=\"/my/root/dir\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7744a70-866d-419b-a083-4a4576b88727",
   "metadata": {},
   "source": [
    "When creating a `DataRegistry` class instance which you intend to use for registering datasets, you may optionally set a default `owner` and/or `owner_type` that will be inherited for all datasets that are registered during that instance. See details in the section \"*Registering new datasets with DataRegistry*\" below for details about `owner` and `owner_type`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d10980-cbd1-40cb-a9f5-45419b44df5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting a global owner and owner_type default value for all datasets that will be registered during this instance\n",
    "# datareg = DataRegistry(owner=\"desc\", owner_type=\"group\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d723a37-4101-496c-b385-0a2644aa7ad8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Registering new datasets with DataRegistry\n",
    "\n",
    "Now that we have made our connection to the database we can register some datasets using the `Registrar` extension of the `DataRegistry` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaa5a7f-ccb1-47d3-9e9b-b62ad32287d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a empty text file as some example data\n",
    "with open(\"dummy_dataset.txt\", \"w\") as f:\n",
    "    f.write(\"some data\")\n",
    "\n",
    "# Add new entry.\n",
    "dataset_id = datareg.Registrar.register_dataset(\n",
    "    \"nersc_tutorial/my_desc_dataset\",\n",
    "    \"1.0.0\",\n",
    "    description=\"An output from some DESC code\",\n",
    "    owner=\"DESC\",\n",
    "    owner_type=\"group\",\n",
    "    is_overwritable=True,\n",
    "    old_location=\"dummy_dataset.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ed3ffb-02f2-42ec-b2c0-643c51f8a295",
   "metadata": {
    "tags": []
   },
   "source": [
    "This will register a new dataset. A few notes:\n",
    "\n",
    "### The relative path\n",
    "\n",
    "Datasets are registered at the data registry shared space under a relative path. For those interested, the eventual full path for the dataset will be `<root_dir>/<owner_type>/<owner>/<relative_path>`. The relative path is one of the two required parameters you must specify when registering a dataset (in the example here our relative path is `nersc_tutorial/my_desc_dataset`).\n",
    "\n",
    "### The version string\n",
    "\n",
    "The second required parameter is the version string, in the semantic format, i.e., MAJOR.MINOR.PATCH. There is also the optional `version_suffix` parameter which can be used to add a suffix to the version string.\n",
    "\n",
    "### Owner and Owner type\n",
    "\n",
    "Datasets are registered under a given `owner`. This can be any string, however it should be informative. If no `owner` is specified, and no global `owner` was set when the `DataRegistry` instance was created, `$USER` is used as the default.\n",
    "\n",
    "One further level of classification is the `owner_type`, which can be one of `user`, `group`, `project` or `production`. If `owner_type` is not specified, and no global `owner_type` was set when the `DataRegistry` instance was created, `user` is the default. Note that `owner_type=production` datasets can only got into the production schema, and can never be overwritten (see next tutorial for more information on the production schema).\n",
    "\n",
    "### Overwriting datasets\n",
    "\n",
    "By default datasets are not overwritable. In that scenario you will need to choose a combination of `relative_path`, `owner` and `owner_type` that is not already taken in the database. For our example we have set it so that the dataset can be overwritten so that it does not raise an error through multiple tests. Note that when a dataset has `is_overwritable=true`, the data in the shared space will overwritten with each registration, but the entry in the data registry database is never lost (a new unique entry is created each time, and the 'old' entries will obtain `true` for their `is_overwritten` row).\n",
    "\n",
    "### Copying the data\n",
    "\n",
    "Registering a dataset does two things; it creates an entry in the DESC data registry database with the appropriate metadata, and it (optionally) copies the dataset contents to a central shared space at NERSC (i.e., under `<root_dir>`). \n",
    "\n",
    "If the data are already at the correct relative path under the NERSC shared space, then only the relative path needs to be provided, and the dataset will then be registered. However it's likely for most users the data will need to be copied from another location at NERSC to the data registry shared space. That initial location may be specified using the `old_location` parameter. \n",
    "\n",
    "In our example we have created a dummy text file as our dataset and ingested it into the data registry, however this can be any file or directory (directories will be recursively copied) at NERSC.\n",
    "\n",
    "### Extra options\n",
    "\n",
    "All the `register_dataset` parameters we do not explicitly specify revert to their default values. For a full list of these options see the documentation [here](http://lsstdesc.org/dataregistry/reference_python.html#the-dregs-class). We would advise you to be as precise as possible when creating entries within the data registry. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6b7862-fd31-43e6-9a50-572b5cd6fff5",
   "metadata": {},
   "source": [
    "## Updating a previously registered dataset with a newer version\n",
    "\n",
    "If a dataset previously registered with the data registry gets updated, you have three options for how to handle the new entry:\n",
    "\n",
    "- You can enter it as a completely new standalone dataset with no links to the previous dataset\n",
    "- You can overwrite the existing dataset with the new data (only if the previous dataset was entered with `is_overwritable=True`)\n",
    "- You can enter it as a new version of the previous dataset (recommended)\n",
    "\n",
    "Unless you are overwriting a previous dataset (when `is_overwritable=True`), you cannot enter a new dataset (even an updated version) using the same relative path. However, datasets can share the same `name` field, which is what we'll use to keep our updated dataset connected to our previous one.\n",
    "\n",
    "Note that in our test dataset we did not specify `name` during registration. The default name for a dataset is the file or directory name taken from its relative path. In our example above this would be `my_desc_dataset`.\n",
    "\n",
    "The combination of `name`, `version` and `version_suffix` for any dataset must be unique. As we are updating a dataset with the same name, we have to make sure to update the version to a new value. One handy feature is automatic version \"bumping\" for datasets, i.e., rather than specifying a new version string manually, one can select \"major\", \"minor\" or \"patch\" for the version string to automatically bump it up. In our case, selecting \"minor\" will automatically generate the version \"1.1.0\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a01c97-a9f5-49b5-b8de-83712ac5f7f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add new entry for an updated dataset with an updated version.\n",
    "dataset_id = datareg.Registrar.register_dataset(\n",
    "    \"nersc_tutorial/my_updated_desc_dataset\",\n",
    "    \"minor\", # Automatically bumps to \"1.1.0\"\n",
    "    description=\"An output from some DESC code (updated)\",\n",
    "    is_overwritable=True,\n",
    "    old_location=\"dummy_dataset.txt\",\n",
    "    name=\"my_desc_dataset\" # Using this name links it to the previous dataset.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf6d38e-ea5e-4916-aa5d-654b2587942d",
   "metadata": {},
   "source": [
    "## Querying the data registry\n",
    "\n",
    "Now that we have covered the basics of dataset registration, we can have a look at how to query entries in the database.\n",
    "\n",
    "Queries are constructed from one or more boolean logic \"filters\", which translate to SQL `WHERE` clauses in the code. \n",
    "\n",
    "For example, to create a filter that will query for all datasets in registry with the name \"my_desc_dataset\" would be as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9901d89-b1d7-48c9-8110-ce16ecba3a7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a filter that queries on the dataset name\n",
    "f = datareg.Query.gen_filter('dataset.name', '==', 'my_desc_dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305a8df6-6967-4280-a5e8-6ea8831eff09",
   "metadata": {},
   "source": [
    "Like with SQL, column names can either be explicit, or not, with the prefix of their table name. For example `name` rather than `dataset.name`. However this would only be valid if the column `name` was unique across all tables, which it is not. We would always recommend being explicit, and including the table name with filters.\n",
    "\n",
    "Now we can pass this filter through to a query using the `Query` extension of the `DataRegistry` class, e.g.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c6d355-dca0-42a1-ae82-7fdbd1a46afa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Query the database\n",
    "results = datareg.Query.find_datasets(['dataset.dataset_id', 'dataset.name', 'dataset.relative_path'], [f])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc05dc6-43e9-4d10-af44-0e4a9353c0b4",
   "metadata": {},
   "source": [
    "Which takes a list of column names we want to return, and a list of filter objects for the query.\n",
    "\n",
    "A SQLAlchemy object is returned, we can look at the results like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0841f472-4ae6-4ca1-810d-6996c58fa14a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for r in results:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48f5445",
   "metadata": {},
   "source": [
    "To get a list of all columns in the database, along with what table they belong to, you can use the `Query.get_all_columns()` function, i.e.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a52029-2908-4056-bc68-4a87f6c3e6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datareg.Query.get_all_columns())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
